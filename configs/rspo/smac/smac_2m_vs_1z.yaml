# cent state 8
base:
  num_train_envs: 16
  n_rollout_threads: 16
  num_eval_envs: 8
  eval_episode_length: 200
  eval_interval: 50
  n_eval_rollout_threads: 8
  num_env_splits: 2

  episode_length: 400
  num_env_steps: 5.0e+6
  ppo_epoch: 10

  use_wandb: False
  wandb_project: rspo-smac
  wandb_group: 2m_1z

  # seed should not be changed throughout iterations
  seed: 1
  seed_specify: True

  # diversity algorithm parameters
  threshold_annealing_schedule: linear
  use_reward_predictor: True
  auto_alpha: 0.5
  likelihood_alpha: 0.25
  likelihood_threshold: 15.0
  prediction_reward_alpha: 0.05
  exploration_reward_alpha: 1.0
  reward_prediction_multiplier: 1.0
  exploration_threshold: 0.5

  n_iterations: 4
  inherit_policy: False
  # archive_policy_dirs:
  #   - results/archive/smac/2m_1z/seed1/iter0/models/model.pt
    # - results/archive/smac/2m_1z/seed2/iter0/models/model.pt
    # - results/archive/smac/2m_1z/seed3/iter0/models/model.pt
  # archive_traj_dirs:
  #   - results/archive/smac/2m_1z/seed1/iter0/models/data.traj
    # - results/archive/smac/2m_1z/seed2/iter0/models/data.traj
    # - results/archive/smac/2m_1z/seed3/iter0/models/data.traj

policy:
  type: rspo
  args:
    hidden_dim: 64
    num_dense_layers: 2
    num_rnn_layers: 1

environment:
  type: smac
  args:
    base:
      map_name: 2m_vs_1z
    eval:
      save_replay: False
      replay_dir: /home/fw/smac_replays_iclr2023/2m_vs_1z/