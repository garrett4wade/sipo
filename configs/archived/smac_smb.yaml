base:
  num_train_envs: 16
  n_rollout_threads: 16
  num_eval_envs: 8
  eval_episode_length: 200
  eval_interval: 50
  n_eval_rollout_threads: 8
  num_env_splits: 2

  episode_length: 400
  num_env_steps: 10.0e+6
  ppo_epoch: 10

  use_wandb: False
  wandb_project: fast_mappo_smac
  wandb_group: smb

  # seed should not be changed throughout iterations
  seed: 1
  seed_specify: True

  # diversity algorithm parameters
  rbf_gamma: 5.0e-3 # if changed, threshold should be probably changed together
  threshold_eps: 9.27
  warmup_fraction: 0.05
  rkhs_action: False

  n_iterations: 2
  ll_max: 10.0
  lagrangian_lr: 0.0
  intrinsic_reward_scaling: 1.0e-3
  inherit_policy: False
  archive_policy_dirs:
    - results/smb/check/1/iter0/models/model.pt
    - results/smb/check/1/iter1/models/model.pt
  archive_traj_dirs:
    - results/smb/check/1/iter0/models/data.traj
    - results/smb/check/1/iter1/models/data.traj

policy:
  type: actor-critic
  args:
    hidden_dim: 64
    num_dense_layers: 2
    num_rnn_layers: 1

environment:
  type: smac
  args:
    base:
      map_name: so_many_baneling
    eval:
      save_replay: True
      replay_dir: /home/fw/workspace/fast_mappo/results/smb/