base:
  num_train_envs: 1024
  n_rollout_threads: 64
  num_eval_envs: 8
  eval_episode_length: 1000
  eval_interval: 100
  n_eval_rollout_threads: 8
  num_env_splits: 2

  log_interval: 10

  episode_length: 5
  num_env_steps: 100.0e+6
  ppo_epoch: 10

  use_wandb: False
  wandb_project: rkhs-humanoid
  wandb_group: humanoid
  wandb_name: humanoid-iter0

  # seed should not be changed throughout iterations
  seed: 1
  seed_specify: True

  # diversity algorithm parameters
  rbf_gamma: 2.0e-2  # if changed, threshold should be probably changed together
  threshold_eps: 8.3
  warmup_fraction: 0.05
  rkhs_action: True

  n_iterations: 4
  ll_max: 10.0
  lagrangian_lr: 0.01
  intrinsic_reward_scaling: 1.0e-1
  inherit_policy: False
  archive_policy_dirs:
    - /localdata/stuff/fw/fast_mappo/results/humanoid/check/1/run1/iter0/models/model.pt
    - /localdata/stuff/fw/fast_mappo/results/humanoid/check/1/run3/iter1/models/model.pt
    - /localdata/stuff/fw/fast_mappo/results/humanoid/check/1/run4/iter2/models/model.pt
  archive_traj_dirs:
    - /localdata/stuff/fw/fast_mappo/results/humanoid/check/1/run1/iter0/models/data.traj
    - /localdata/stuff/fw/fast_mappo/results/humanoid/check/1/run3/iter1/models/data.traj
    - /localdata/stuff/fw/fast_mappo/results/humanoid/check/1/run4/iter2/models/data.traj

policy:
  type: actor-critic
  args:
    hidden_dim: 128
    num_dense_layers: 2
    num_rnn_layers: 0
    std_type: fixed
    init_log_std: -0.5

environment:
  type: gym_mujoco
  args:
    base:
      env_name: Humanoid-v3
