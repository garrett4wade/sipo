base:
  num_train_envs: 32
  n_rollout_threads: 8
  num_eval_envs: 32
  eval_episodes: 32
  eval_interval: 100
  n_eval_rollout_threads: 32
  num_env_splits: 2

  episode_length: 200
  num_env_steps: 10.0e+6
  ppo_epoch: 15

  use_wandb: False
  wandb_project: rkhs-halfcheetah
  wandb_group: check

  # seed should not be changed throughout iterations
  seed: 1
  seed_specify: True

  # diversity algorithm parameters
  rbf_gamma: 5.0e-3  # if changed, threshold should be probably changed together
  threshold_eps: 10.9
  warmup_fraction: 0.05
  rkhs_action: True

  n_iterations: 6
  ll_max: 10.0
  lagrangian_lr: 0.01
  intrinsic_reward_scaling: 1.0e-1
  archive_policy_dirs:
      - results/halfcheetah/check/1/run2/iter0/models/model.pt
  archive_traj_dirs:
      - results/halfcheetah/check/1/run2/iter0/models/data.traj

policy:
  type: actor-critic
  args:
    hidden_dim: 128
    num_dense_layers: 2
    num_rnn_layers: 0
    std_type: separate_learnable
    init_log_std: -0.5

environment:
  type: gym_mujoco
  args:
    base:
      env_name: HalfCheetah-v4
